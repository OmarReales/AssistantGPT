{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq6nk33/sO+fsZdQDyUnYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarReales/AssistantGPT/blob/main/AssistantAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-generativeai #dependencias geminiAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ACgM3JogbOI",
        "outputId": "4e2b5702-2210-4765-8b55-8d4d53825d9b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.2)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.20.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "import sys\n",
        "from google.colab import userdata\n",
        "from abc import ABC, abstractmethod\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Esta función se usa para dejar el formato Markdown que devuelve Gemini en formato compatible con Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "wzGYCkx-glAd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuramos nuestra instancia del modelo con nuestra API key\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key = GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "bPvo5_tzhzak"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.5,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"Eres un asistente de estudio inteligente creado para ayudar a los estudiantes a comprender y aprender una amplia variedad de temas. Tu objetivo es proporcionar explicaciones claras y concisas, responder preguntas, ayudar con la resolución de problemas y ofrecer consejos útiles para el estudio. Debes responder de manera amigable, paciente y comprensiva, adaptando tus respuestas al nivel de conocimiento del usuario. Evita el uso de jerga técnica innecesaria y proporciona ejemplos prácticos cuando sea posible. Si no tienes suficiente información para responder una pregunta, ofrécele al usuario sugerencias sobre cómo investigar más.\"\n",
        ")"
      ],
      "metadata": {
        "id": "Bn83HeK0iMus"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cierra el programa\n",
        "def cerrar():\n",
        "    print (\"Espero haber sido de ayuda! saludos\")\n",
        "    sys.exit()\n",
        "\n",
        "# Función que solicita una respuesta S/N del usuario\n",
        "def continua(texto_pregunta):\n",
        "    resp = input(f'{texto_pregunta} [S/N]: ').upper()\n",
        "    if resp == 'S':\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# Función que devuelve un título centrado con guiones\n",
        "def titulo(texto:str,largo:int=80):\n",
        "    return f\"{'-'*largo}\\n{texto.title().center(largo)}\\n{'-'*largo}\"\n",
        "\n",
        "\n",
        "# Función que calcula el largo de la opción más larga en un menú\n",
        "def obtener_largo_opcion_mas_larga(tupla_opciones):\n",
        "    maximo_largo = -float('inf')\n",
        "    for i,texto in enumerate(tupla_opciones):\n",
        "        if len(texto) > maximo_largo:\n",
        "            maximo_largo = len(texto)\n",
        "    return maximo_largo\n",
        "\n",
        "# Función que verifica si una cadena es un entero\n",
        "def isint(str_numero:str)->bool:\n",
        "    try:                    # Intenta convertir str_numero a int\n",
        "        int(str_numero)\n",
        "    except:                 # Si no puede convertirlo devuelve False\n",
        "        return False\n",
        "    return True             # Si puede convertirlo devuelve True\n",
        "\n",
        "\n",
        "# Función que lee un entero en un rango determinado\n",
        "def leer_entero(mensaje:str='Ingrese un entero: ',minimo:int=-float('inf'),maximo:int=float('inf'))->int:\n",
        "    todo_ok = False\n",
        "    while not todo_ok:\n",
        "        cadena = input(mensaje)\n",
        "        if isint(cadena):\n",
        "            numero = int(cadena)\n",
        "            if minimo <= numero <= maximo:\n",
        "                todo_ok = True\n",
        "            else:\n",
        "                print(f\"Número {numero} fuera de rango [{minimo}] .. [{maximo}]\")\n",
        "        else:\n",
        "            print(f\"{cadena} No es un int.\")\n",
        "    return int(cadena)\n",
        "\n",
        "# Función que muestra un menú con las opciones de una tupla\n",
        "def opcion(tupla_opciones:str)->int:\n",
        "    #La primera opcion es el titulo\n",
        "    #Las demas son las opciones\n",
        "    largo = obtener_largo_opcion_mas_larga(tupla_opciones)\n",
        "    for index,opcion in enumerate(tupla_opciones):\n",
        "        if index == 0:\n",
        "            print(titulo(opcion,largo))\n",
        "        else:\n",
        "            print(opcion.title())\n",
        "    return leer_entero(\"Ingrese una opcion: \",1,4)"
      ],
      "metadata": {
        "id": "SVD-lKIFjhSE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class studyAssistant(ABC):\n",
        "    def __init__(self) -> None:\n",
        "        self.__nombre = \"AssistantGPT\"\n",
        "        self.__respuesta = None\n",
        "        self.__consulta = None\n",
        "        self.__OPCIONES = [\"Escoge alguna opcion\",\n",
        "        \"1. Asistente de estudio\",\n",
        "        \"2. Salir del programa\"\n",
        "        ]\n",
        "        self._OPCIONES_ASISTENTE =[\"Escoje alguna opcion\",\n",
        "        \"1. Quiero que me expliques sobre un tema\",\n",
        "        \"2. Quiero un resumen de un texto\",\n",
        "        \"3. Salir del programa\"\n",
        "        ]\n",
        "\n",
        "#Este metodo es para preguntarle al usuario si tiene una historia o crear una historia en el momento y trabajar sobre ello\n",
        "    def consultar_asistente(self) -> None:\n",
        "        opciones = self._OPCIONES_ASISTENTE\n",
        "        opcion_seleccionada = opcion(opciones)\n",
        "\n",
        "        if opcion_seleccionada == 1:\n",
        "            self.explicar_tema()\n",
        "        elif opcion_seleccionada == 2:\n",
        "            self.crear_resumen()\n",
        "        elif opcion_seleccionada == 3:\n",
        "            cerrar()\n",
        "        else:\n",
        "            raise ValueError(\"Marque una opción válida\")\n",
        "\n",
        "#Metodo para crear una historia segun las especificaciones del usuario\n",
        "    def crear_resumen (self) ->str:\n",
        "        inputText = input(\"Indiqua el tema que quieras que resuma: \")\n",
        "\n",
        "        contexto = f\"Creame un resumen de no mas de 500 palabras sobre: '{inputText}' \"\n",
        "        conversacion = [{\"role\": \"user\", \"content\": contexto}]\n",
        "\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        response = model.generate_content(f\"{inputText} resume la respuesta en 500 palabras maximo y que sea facil de identificar los puntos claves\")\n",
        "\n",
        "        generated_text = response.candidates[0].content.parts[0].text\n",
        "        print(\"AssistantGPT: \\n\", generated_text)\n",
        "\n",
        "        self.__resumen = generated_text\n",
        "\n",
        "        if continua(\"Quieres hacer una consulta?\"):\n",
        "            self._interfaz()\n",
        "        else:\n",
        "            cerrar()\n",
        "\n",
        "\n",
        "# Método para obtener y enviar el resumen al asistente de estudio\n",
        "    def mandar_resumen(self) ->str:\n",
        "        self.__resumen = input(\"Escribe el texto a resumir: \")\n",
        "        print(f\"\\n El texto que has ingresado es: \\n''{self.__resumen}''\")\n",
        "        return self.__resumen\n",
        "\n",
        "# Método para procesar el resumen y realizar consultas\n",
        "    def procesar_resumen(self) -> None:\n",
        "        self.__consulta = self.consulta() #Ejemplo \"Quiero que me hagas una lluvia de ideas para continuar la historia. Como maximo 2 respuestas\"\n",
        "\n",
        "        contexto = f\"{self.__resumen}\\nUsuario: {self.__consulta}\"\n",
        "        conversacion = [{\"role\": \"user\", \"content\": contexto}]\n",
        "\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        response = model.generate_content(f\"{self.__consulta}\")\n",
        "\n",
        "        generated_text = response.candidates[0].content.parts[0].text\n",
        "        print(\"AssistantGPT: \\n\", generated_text)\n",
        "\n",
        "        if continua(\"Alguna otra consulta?\"):\n",
        "            self._interfaz()\n",
        "        else:\n",
        "            cerrar()\n",
        "# Método para explicar un tema y realizar consultas\n",
        "    def explicar_tema(self) -> None:\n",
        "        tema = input(\"Indica el tema que quieres que te explique: \")\n",
        "        contexto = f\"Explicame el siguiente tema: '{tema}'\"\n",
        "        conversacion = [{\"role\": \"user\", \"content\": contexto}]\n",
        "\n",
        "        try:\n",
        "            model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "            response = model.generate_content(contexto)\n",
        "            generated_text = response.candidates[0].content.parts[0].text\n",
        "            print(\"AssistantGPT: \\n\", generated_text)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "        if continua(\"Quiere hacer una consulta?\"):\n",
        "            self._interfaz()\n",
        "        else:\n",
        "            cerrar()\n",
        "\n",
        "# Método para recibir la consulta del usuario\n",
        "    def consulta(self) -> str:\n",
        "        return str(input(\"\\n Escriba la solicitud que desee realizar: \"))\n",
        "\n",
        "    def __str__ (self) ->str:\n",
        "        return titulo(\"Bienvenido al Asistente de estudio\")\n",
        "\n",
        "    def nombre (self) ->str:\n",
        "        return self.__nombre\n",
        "\n",
        "    def _interfaz(self) ->None:\n",
        "        self.__respuesta = opcion(self.__OPCIONES)\n",
        "\n",
        "        if self.__respuesta == 1:\n",
        "            self.consultar_asistente()\n",
        "        elif self.__respuesta == 2:\n",
        "            cerrar()\n",
        "        else:\n",
        "            raise ValueError(\"Marque una opción válida\")"
      ],
      "metadata": {
        "id": "IDDsgZqukE-3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defino la parte principal del programa para que pueda iniciarse\n",
        "def main():\n",
        "    asistente = studyAssistant()\n",
        "\n",
        "    while True:\n",
        "        print(titulo(f\"Bienvenido a *{asistente.nombre()}*\"))\n",
        "        asistente.consultar_asistente()\n",
        "        asistente._interfaz()\n",
        "\n",
        "# Verificar si este archivo es el punto de entrada principal\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YNHgMZxqmOci",
        "outputId": "03aaf8fa-d559-4e42-d4f7-a445dbd2abad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "                          Bienvenido A *Assistantgpt*                           \n",
            "--------------------------------------------------------------------------------\n",
            "----------------------------------------\n",
            "          Escoje Alguna Opcion          \n",
            "----------------------------------------\n",
            "1. Quiero Que Me Expliques Sobre Un Tema\n",
            "2. Quiero Un Resumen De Un Texto\n",
            "3. Salir Del Programa\n",
            "Ingrese una opcion: 1\n",
            "Indica el tema que quieres que te explique: calentamiento global\n",
            "AssistantGPT: \n",
            " ## El calentamiento global: Una crisis planetaria\n",
            "\n",
            "El calentamiento global se refiere al **aumento a largo plazo de la temperatura promedio de la Tierra**, provocado principalmente por la **emisión de gases de efecto invernadero** a la atmósfera. Estos gases atrapan el calor del sol, provocando un aumento de la temperatura global.\n",
            "\n",
            "**Aquí algunos puntos clave sobre el calentamiento global:**\n",
            "\n",
            "**1. Causas:**\n",
            "* **Emisiones de gases de efecto invernadero:** Los principales responsables son el dióxido de carbono (CO2), metano (CH4) y óxido nitroso (N2O), liberados por actividades humanas como la quema de combustibles fósiles, la deforestación y la agricultura.\n",
            "* **Otras causas:** La variabilidad solar, las erupciones volcánicas y cambios en la órbita de la Tierra también pueden afectar el clima, pero su impacto es menor en comparación con las emisiones humanas.\n",
            "\n",
            "**2. Efectos:**\n",
            "* **Aumento del nivel del mar:** El derretimiento de glaciares y capas de hielo aumenta el volumen de agua en los océanos, lo que eleva el nivel del mar y amenaza las zonas costeras.\n",
            "* **Eventos climáticos extremos:** Se intensifican las olas de calor, sequías, inundaciones y tormentas, causando daños a la infraestructura y la agricultura.\n",
            "* **Acidificación de los océanos:** El CO2 absorbido por el océano aumenta su acidez, lo que afecta a la vida marina y los ecosistemas.\n",
            "* **Pérdida de biodiversidad:** El cambio climático altera los hábitats de plantas y animales, amenazando su supervivencia.\n",
            "* **Problemas de salud:** El aumento de las temperaturas y la contaminación del aire provocan enfermedades respiratorias, cardiovasculares y otras complicaciones de salud.\n",
            "\n",
            "**3. Soluciones:**\n",
            "* **Reducción de emisiones:** Es fundamental disminuir la dependencia de los combustibles fósiles y optar por energías renovables como la solar, eólica e hidráulica.\n",
            "* **Eficiencia energética:** Se debe mejorar la eficiencia energética en hogares, empresas y transporte para reducir el consumo de energía.\n",
            "* **Conservación de los bosques:** Los bosques absorben CO2 de la atmósfera, por lo que su protección es crucial para combatir el calentamiento global.\n",
            "* **Tecnologías de captura de carbono:** Existen tecnologías que permiten capturar y almacenar el CO2 emitido por las industrias.\n",
            "\n",
            "**4. Importancia:**\n",
            "El calentamiento global es una amenaza real para el futuro de nuestro planeta. Sus efectos ya son evidentes y se intensificarán si no se toman medidas para reducir las emisiones de gases de efecto invernadero.\n",
            "\n",
            "**En resumen, el calentamiento global es una crisis ambiental que requiere de la acción global y urgente para mitigar sus impactos y garantizar un futuro sostenible para la humanidad.**\n",
            "\n",
            "Quiere hacer una consulta? [S/N]: s\n",
            "-----------------------\n",
            "  Escoge Alguna Opcion \n",
            "-----------------------\n",
            "1. Asistente De Estudio\n",
            "2. Salir Del Programa\n",
            "Ingrese una opcion: 1\n",
            "----------------------------------------\n",
            "          Escoje Alguna Opcion          \n",
            "----------------------------------------\n",
            "1. Quiero Que Me Expliques Sobre Un Tema\n",
            "2. Quiero Un Resumen De Un Texto\n",
            "3. Salir Del Programa\n",
            "Ingrese una opcion: 3\n",
            "Espero haber sido de ayuda! saludos\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}